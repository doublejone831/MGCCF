{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "11.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\.conda\\envs\\Jupyter_Notebook\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "# edge index가 source와 dest로 주어질때\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#edge index가 각각의 edge가 하나의 리스트로 주어질때\n",
    "edge_index = torch.tensor([[0, 1],\n",
    "                           [1, 0],\n",
    "                           [1, 2],\n",
    "                           [2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bipartite_sage example\n",
    "https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/bipartite_sage.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Embedding, Linear\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import MovieLens\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: scipy in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from sentence-transformers) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from sentence-transformers) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from sentence-transformers) (4.29.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.1.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: click in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.15.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\.conda\\envs\\jupyter_notebook\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = osp.join(osp.dirname('C:/Users/PC/Desktop/MGCCF/PyG_tut.ipynb'), '../../data/MovieLens')\n",
    "dataset = MovieLens(path, model_name='all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovie\u001b[0m={ x=[9742, 404] },\n",
       "  \u001b[1muser\u001b[0m={ num_nodes=610 },\n",
       "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
       "    edge_index=[2, 100836],\n",
       "    edge_label=[100836]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-mapping\n",
    "data['user'].x = torch.arange(0,data['user'].num_nodes)\n",
    "data['movie'].num_nodes = len(data['movie']['x'])\n",
    "data['movie'].x = torch.arange(0,data['movie'].num_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4,  ..., 5, 5, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['user','movie'].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 4., 4.,  ..., 5., 5., 3.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['user','movie'].edge_label = data['user','movie'].edge_label.float()\n",
    "data['user','movie'].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = T.ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    x=[9742],\n",
       "    num_nodes=9742\n",
       "  },\n",
       "  \u001b[1muser\u001b[0m={\n",
       "    num_nodes=610,\n",
       "    x=[610]\n",
       "  },\n",
       "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
       "    edge_index=[2, 100836],\n",
       "    edge_label=[100836]\n",
       "  },\n",
       "  \u001b[1m(movie, rev_rates, user)\u001b[0m={\n",
       "    edge_index=[2, 100836],\n",
       "    edge_label=[100836]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['movie', 'rev_rates', 'user'].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    x=[9742],\n",
       "    num_nodes=9742\n",
       "  },\n",
       "  \u001b[1muser\u001b[0m={\n",
       "    num_nodes=610,\n",
       "    x=[610]\n",
       "  },\n",
       "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
       "    edge_index=[2, 100836],\n",
       "    edge_label=[100836]\n",
       "  },\n",
       "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 100836] }\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing data splits...\n",
      "Split Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing data splits...\")\n",
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0, # 레이팅으로 하는 것의 경우 이것을 0.0 이 아닌 다른 값으로 잡으면 오류 발생\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=[('user', 'rates', 'movie')],\n",
    "    rev_edge_types=[('movie', 'rev_rates', 'user')]\n",
    ")(data)\n",
    "print(\"Split Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metapath = [('movie', 'rev_rates', 'user'), ('user', 'rates', 'movie')]\n",
    "train_data = T.AddMetaPaths(metapaths=[metapath])(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, edge_weight = gcn_norm(\n",
    "    train_data['movie', 'movie'].edge_index,\n",
    "    num_nodes=train_data['movie'].num_nodes,\n",
    "    add_self_loops=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = train_data['movie', 'movie'].edge_index[:, edge_weight > 0.002]\n",
    "\n",
    "train_data['movie', 'metapath_0', 'movie'].edge_index = edge_index\n",
    "val_data['movie', 'metapath_0', 'movie'].edge_index = edge_index\n",
    "test_data['movie', 'metapath_0', 'movie'].edge_index = edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  metapath_dict={ (movie, metapath_0, movie)=[2] },\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    x=[9742],\n",
       "    num_nodes=9742\n",
       "  },\n",
       "  \u001b[1muser\u001b[0m={\n",
       "    num_nodes=610,\n",
       "    x=[610]\n",
       "  },\n",
       "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
       "    edge_index=[2, 80670],\n",
       "    edge_label=[80670],\n",
       "    edge_label_index=[2, 80670]\n",
       "  },\n",
       "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 80670] },\n",
       "  \u001b[1m(movie, metapath_0, movie)\u001b[0m={ edge_index=[2, 79981] }\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieGNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = SAGEConv(-1, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserGNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv3 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        movie_x = self.conv1(\n",
    "            x_dict['movie'],\n",
    "            edge_index_dict[('movie', 'metapath_0', 'movie')],\n",
    "        ).relu()\n",
    "\n",
    "        user_x = self.conv2(\n",
    "            (x_dict['movie'], x_dict['user']),\n",
    "            edge_index_dict[('movie', 'rev_rates', 'user')],\n",
    "        ).relu()\n",
    "\n",
    "        user_x = self.conv3(\n",
    "            (movie_x, user_x),\n",
    "            edge_index_dict[('movie', 'rev_rates', 'user')],\n",
    "        ).relu()\n",
    "\n",
    "        return self.lin(user_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_src, z_dst, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_src[row], z_dst[col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_movies, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.user_emb = Embedding(num_users, hidden_channels)\n",
    "        self.movie_emb = Embedding(num_movies, hidden_channels)\n",
    "        self.user_encoder = UserGNNEncoder(hidden_channels, out_channels)\n",
    "        self.movie_encoder = MovieGNNEncoder(hidden_channels, out_channels)\n",
    "        self.decoder = EdgeDecoder(out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = {}\n",
    "        x_dict['user'] = self.user_emb(x_dict['user'])\n",
    "        x_dict['movie'] = self.movie_emb(x_dict['movie'])\n",
    "        z_dict['user'] = self.user_encoder(x_dict, edge_index_dict)\n",
    "        z_dict['movie'] = self.movie_encoder(\n",
    "            x_dict['movie'],\n",
    "            edge_index_dict[('movie', 'metapath_0', 'movie')],\n",
    "        )\n",
    "        return self.decoder(z_dict['user'], z_dict['movie'], edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(data['user'].num_nodes, data['movie'].num_nodes, hidden_channels=64, out_channels=64)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(\n",
    "        train_data.x_dict,\n",
    "        train_data.edge_index_dict,\n",
    "        train_data['user', 'movie'].edge_label_index,\n",
    "    )\n",
    "    loss = F.mse_loss(out, train_data['user', 'movie'].edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    out = model(\n",
    "        data.x_dict,\n",
    "        data.edge_index_dict,\n",
    "        data['user', 'movie'].edge_label_index,\n",
    "    ).clamp(min=0, max=5)\n",
    "    rmse = F.mse_loss(out, data['user', 'movie'].edge_label).sqrt()\n",
    "    return float(rmse)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(data):\n",
    "    model.eval()\n",
    "    out = model(\n",
    "        data.x_dict,\n",
    "        data.edge_index_dict,\n",
    "        data['user', 'movie'].edge_label_index,\n",
    "    ).clamp(min=0, max=5)\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "for epoch in range(1, 701):\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    test_rmse = test(test_data)\n",
    "    print(f'Epoch: {epoch:04d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.0233, 3.9060, 2.6514,  ..., 3.5669, 2.9768, 2.3004], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter_Notebook",
   "language": "python",
   "name": "jupyter_notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
