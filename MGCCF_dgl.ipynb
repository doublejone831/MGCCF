{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Builder\n",
    "from collections import namedtuple\n",
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype, is_categorical\n",
    "import dgl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from \"module\" import * 일때 *에 무엇을 포함 시킬 것 인지 \n",
    "# __all__ = ['PandasGraphBulder']\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "class graph_builder(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(graph_builder,self).__init__()\n",
    "\n",
    "    def load_data(self, path, User_feature_path = None, Item_feature_path = None):\n",
    "        \"\"\" \n",
    "        Load the data from file path and build the graph\n",
    "        Parameter:\n",
    "        train_path : str => file path for train data set\n",
    "        test_path : str => file path for test data set\n",
    "        User_feature_path : str , default = None => file path for user data \n",
    "        Item_feature_path : str , default = None => file path for item data \n",
    "        Return:\n",
    "        Without Feature : rating graph as g\n",
    "        Without User Feature : user_feature, dgl graph as g\n",
    "        Without Item Feature : item_feature, dgl graph as g\n",
    "        With Feature : item_feature, user_feature, dgl graph as g\n",
    "        \"\"\"\n",
    "        if os.path.exists(path):\n",
    "            self.edges = pd.read_table(path, names=[\"user\",\"item\",\"timestamp\"], sep=\" \",dtype={'user':np.int64,'item':np.int64})\n",
    "            self.num_user_node = len(self.edges['user'].unique())\n",
    "            self.num_item_node = len(self.edges['item'].unique())\n",
    "            user_item_src = self.edges['user']\n",
    "            user_item_dst = self.edges['item']\n",
    "\n",
    "            print(f\"User node : {self.num_user_node}\\n \\\n",
    "                  Item node : {self.num_item_node}\\n \\\n",
    "                  edges : {len(self.edges)}\")\n",
    "        else:\n",
    "            FileNotFoundError(f\"There are No train data in {path}\")\n",
    "\n",
    "        if User_feature_path != None:\n",
    "            if os.path.exists(User_feature_path):\n",
    "                self.user_feature = pd.read_table(User_feature_path)\n",
    "            else:\n",
    "                FileNotFoundError(f\"There are No user feature data in {User_feature_path}\")\n",
    "        else:\n",
    "            self.user_feature = None\n",
    "        if Item_feature_path != None:\n",
    "            if os.path.exists(Item_feature_path):\n",
    "                self.item_feature = pd.read_table(Item_feature_path)\n",
    "            else:\n",
    "                FileNotFoundError(f\"There are No user feature data in {Item_feature_path}\")\n",
    "        else:\n",
    "            self.user_feature = None\n",
    "\n",
    "        data_dict = {\n",
    "            (\"user\", \"ui\", \"item\"): (user_item_src, user_item_dst),\n",
    "            (\"item\", \"iu\", \"user\"): (user_item_dst, user_item_src),\n",
    "        }\n",
    "        num_nodes_dict = { \"user\" : self.num_user_node, \"item\" : self.num_item_node}\n",
    "\n",
    "        self.g = dgl.heterograph(data_dict, num_nodes_dict)\n",
    "        \n",
    "        return\n",
    "\n",
    "    def sample(self):\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MGCCF(nn.Module):\n",
    "    def __init__(self, data, emb_size, n_layers):\n",
    "        super(MGCCF, self).__init__()\n",
    "        self.n_user = data.num_user_node\n",
    "        self.n_item = data.num_item_node\n",
    "        self.emb_size = emb_size\n",
    "        # 512\n",
    "        self.layers = n_layers\n",
    "        # [128, 64 or 128]\n",
    "\n",
    "\n",
    "    def init_weight(self):\n",
    "        # xavier init\n",
    "        initializer = nn.init.xavier_uniform_\n",
    "\n",
    "        self.embedding_dict = nn.ParameterDict({\n",
    "            'user_emb': nn.Parameter(initializer(torch.empty(self.n_user,\n",
    "                                                 self.emb_size))),\n",
    "            'item_emb': nn.Parameter(initializer(torch.empty(self.n_item,\n",
    "                                                 self.emb_size)))\n",
    "        })\n",
    "        \n",
    "        #init the paramenter\n",
    "        self.user_weight_dict = nn.ParameterDict()\n",
    "        layers = [self.emb_size] + self.layers\n",
    "        for k in range(len(self.layers)):\n",
    "            self.user_weight_dict.update({'W_gc_%d'%k: nn.Parameter(initializer(torch.empty(layers[k],\n",
    "                                                                      layers[k+1])))})\n",
    "            # Aggregation layer weight(Q)\n",
    "            self.user_weight_dict.update({'W_ag_%d'%k: nn.Parameter(initializer(torch.empty(layers[k],\n",
    "                                                                      layers[k+1])))})\n",
    "        \n",
    "        self.item_weight_dict = nn.ParameterDict()\n",
    "        layers = [self.emb_size] + self.layers\n",
    "        for k in range(len(self.layers)):\n",
    "            self.item_weight_dict.update({'W_gc_%d'%k: nn.Parameter(initializer(torch.empty(layers[k],\n",
    "                                                                      layers[k+1])))})\n",
    "            # Aggregation layer weight(Q)\n",
    "            self.item_weight_dict.update({'W_ag_%d'%k: nn.Parameter(initializer(torch.empty(layers[k],\n",
    "                                                                      layers[k+1])))})\n",
    "        \n",
    "    def information_fusion(hidden, z, s):\n",
    "        return hidden + z + s\n",
    "    \n",
    "\n",
    "    def create_bpr_loss(self, users, pos_items, neg_items):\n",
    "        pos_scores = torch.sum(torch.mul(users, pos_items), axis=1)\n",
    "        neg_scores = torch.sum(torch.mul(users, neg_items), axis=1)\n",
    "\n",
    "        maxi = nn.LogSigmoid()(pos_scores - neg_scores)\n",
    "\n",
    "        mf_loss = -1 * torch.mean(maxi)\n",
    "\n",
    "        # cul regularizer\n",
    "        regularizer = (torch.norm(users) ** 2\n",
    "                       + torch.norm(pos_items) ** 2\n",
    "                       + torch.norm(neg_items) ** 2) / 2\n",
    "        emb_loss = self.decay * regularizer / self.batch_size\n",
    "\n",
    "        return mf_loss + emb_loss, mf_loss, emb_loss\n",
    "    \n",
    "    \n",
    "    def forward():\n",
    "        # User Embedding Gcn\n",
    "\n",
    "        # Item Embedding Gcn\n",
    "\n",
    "        # Skip-Connection\n",
    "\n",
    "        # MGE\n",
    "\n",
    "        # Information Fusion\n",
    "\n",
    "        # "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter_Notebook",
   "language": "python",
   "name": "jupyter_notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
